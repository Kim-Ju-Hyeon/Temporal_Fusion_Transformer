{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b62984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8476c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../M5_Dataset/tft_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68478d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 135870 entries, 0 to 135869\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   store_id      135870 non-null  category      \n",
      " 1   dept_id       135870 non-null  category      \n",
      " 2   state_id      135870 non-null  category      \n",
      " 3   cat_id        135870 non-null  category      \n",
      " 4   Node          135870 non-null  category      \n",
      " 5   d             135870 non-null  int16         \n",
      " 6   sold          135870 non-null  float64       \n",
      " 7   date          135870 non-null  datetime64[ns]\n",
      " 8   weekday       135870 non-null  category      \n",
      " 9   wday          135870 non-null  category      \n",
      " 10  month         135870 non-null  category      \n",
      " 11  event_name_1  135870 non-null  category      \n",
      " 12  event_type_1  135870 non-null  category      \n",
      " 13  event_name_2  135870 non-null  category      \n",
      " 14  event_type_2  135870 non-null  category      \n",
      " 15  snap_CA       135870 non-null  category      \n",
      " 16  snap_TX       135870 non-null  category      \n",
      " 17  snap_WI       135870 non-null  category      \n",
      "dtypes: category(15), datetime64[ns](1), float64(1), int16(1)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc423db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"month\"] = data[\"month\"].astype(str).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5cf4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_days = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "snap_days = ['snap_CA', 'snap_TX', 'snap_WI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37c54561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[snap_days] = data[snap_days].astype(str).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eda03e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data[data.d < 1912]\n",
    "test_dataset = data[data.d >= 1912]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9ac627f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 30\n",
    "max_encoder_length = 90\n",
    "training_cutoff = train_dataset[\"d\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0c6ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder = train_dataset[lambda x: x.d > x.d.max() - max_encoder_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d92af6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.concat([test_encoder, test_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ad6ea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cutoff = test_dataset[\"d\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf77f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_dataset[lambda x: x.d <= training_cutoff],\n",
    "    time_idx=\"d\",\n",
    "    target=\"sold\",\n",
    "    group_ids=[\"Node\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"Node\", \"store_id\", \"dept_id\", \"state_id\", 'cat_id'],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\", \"snap_days\"],\n",
    "    variable_groups={\"special_days\": special_days, \"snap_days\": snap_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"d\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"sold\"],\n",
    "\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True\n",
    ")\n",
    "\n",
    "test_dataset = TimeSeriesDataSet(\n",
    "    test_dataset[lambda x: x.d <= test_cutoff],\n",
    "    time_idx=\"d\",\n",
    "    target=\"sold\",\n",
    "    group_ids=[\"Node\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"Node\", \"store_id\", \"dept_id\", \"state_id\", 'cat_id'],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\", \"snap_days\"],\n",
    "    variable_groups={\"special_days\": special_days, \"snap_days\": snap_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"d\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"sold\"],\n",
    "\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e78b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders for model\n",
    "batch_size = 128\n",
    "\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "val_dataloader = test_dataset.to_dataloader(train=False, batch_size=batch_size , num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6dd27cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 22\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:19<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 21.9k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(22)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=4,\n",
    "    dropout=0.3,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb7a46bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.7 K \n",
      "3  | prescalers                         | ModuleDict                      | 96    \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 2.5 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 2.2 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.6 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 676   \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "21.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.9 K    Total params\n",
      "0.088     Total estimated model params size (MB)\n",
      "Global seed set to 22\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:27<00:00,  3.81it/s]Restored states from the checkpoint file at /Users/juhyeonkim/Dropbox/내 Mac (JuHyeonui-iMac.local)/Documents/graphNN/graphNN/lr_find_temp_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.06760829753919811\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-a92b5627800b>:12: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8215bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 21.9k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=20, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    gpus=0,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=res.suggestion(),\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.3,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "36c9793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.7 K \n",
      "3  | prescalers                         | ModuleDict                      | 96    \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 2.5 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 2.2 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.6 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 676   \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "21.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.9 K    Total params\n",
      "0.088     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  38%|███▊      | 30/79 [00:23<00:37,  1.29it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding best initial lr: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  39%|███▉      | 31/79 [00:23<00:36,  1.31it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  41%|████      | 32/79 [00:41<01:00,  1.28s/it, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  42%|████▏     | 33/79 [00:41<00:57,  1.25s/it, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  44%|████▍     | 35/79 [00:41<00:52,  1.18s/it, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  47%|████▋     | 37/79 [00:41<00:47,  1.12s/it, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  49%|████▉     | 39/79 [00:41<00:42,  1.07s/it, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  52%|█████▏    | 41/79 [00:41<00:38,  1.02s/it, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  54%|█████▍    | 43/79 [00:42<00:35,  1.02it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  57%|█████▋    | 45/79 [00:42<00:31,  1.07it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  59%|█████▉    | 47/79 [00:42<00:28,  1.11it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  62%|██████▏   | 49/79 [00:42<00:25,  1.15it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  65%|██████▍   | 51/79 [00:42<00:23,  1.20it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  67%|██████▋   | 53/79 [00:42<00:21,  1.24it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  70%|██████▉   | 55/79 [00:42<00:18,  1.28it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  72%|███████▏  | 57/79 [00:43<00:16,  1.32it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  75%|███████▍  | 59/79 [00:43<00:14,  1.36it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  77%|███████▋  | 61/79 [00:43<00:12,  1.41it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  80%|███████▉  | 63/79 [00:43<00:11,  1.44it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  82%|████████▏ | 65/79 [00:43<00:09,  1.48it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  85%|████████▍ | 67/79 [00:43<00:07,  1.53it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  87%|████████▋ | 69/79 [00:44<00:06,  1.57it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  90%|████████▉ | 71/79 [00:44<00:04,  1.61it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  92%|█████████▏| 73/79 [00:44<00:03,  1.65it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  95%|█████████▍| 75/79 [00:44<00:02,  1.69it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0:  97%|█████████▋| 77/79 [00:44<00:01,  1.73it/s, loss=27.3, v_num=7, val_loss=70.90, train_loss_step=23.20]\n",
      "Epoch 0: 100%|██████████| 79/79 [00:46<00:00,  1.71it/s, loss=27.3, v_num=7, val_loss=26.90, train_loss_step=27.60, train_loss_epoch=31.10]\n",
      "Epoch 1:  39%|███▉      | 31/79 [00:22<00:34,  1.40it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  41%|████      | 32/79 [00:39<00:58,  1.24s/it, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  42%|████▏     | 33/79 [00:39<00:55,  1.20s/it, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  43%|████▎     | 34/79 [00:39<00:52,  1.17s/it, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  46%|████▌     | 36/79 [00:40<00:47,  1.11s/it, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  48%|████▊     | 38/79 [00:40<00:43,  1.06s/it, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  51%|█████     | 40/79 [00:40<00:39,  1.01s/it, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  53%|█████▎    | 42/79 [00:40<00:35,  1.03it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  56%|█████▌    | 44/79 [00:40<00:32,  1.08it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  58%|█████▊    | 46/79 [00:40<00:29,  1.12it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  61%|██████    | 48/79 [00:41<00:26,  1.17it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  63%|██████▎   | 50/79 [00:41<00:23,  1.21it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  66%|██████▌   | 52/79 [00:41<00:21,  1.25it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  68%|██████▊   | 54/79 [00:41<00:19,  1.30it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  71%|███████   | 56/79 [00:41<00:17,  1.34it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  73%|███████▎  | 58/79 [00:41<00:15,  1.38it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  76%|███████▌  | 60/79 [00:42<00:13,  1.43it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  78%|███████▊  | 62/79 [00:42<00:11,  1.47it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  81%|████████  | 64/79 [00:42<00:09,  1.51it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  84%|████████▎ | 66/79 [00:42<00:08,  1.55it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  86%|████████▌ | 68/79 [00:42<00:06,  1.59it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  89%|████████▊ | 70/79 [00:42<00:05,  1.64it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  91%|█████████ | 72/79 [00:43<00:04,  1.67it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  94%|█████████▎| 74/79 [00:43<00:02,  1.72it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  96%|█████████▌| 76/79 [00:43<00:01,  1.76it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1:  99%|█████████▊| 78/79 [00:43<00:00,  1.80it/s, loss=24.9, v_num=7, val_loss=26.90, train_loss_step=27.50, train_loss_epoch=31.10]\n",
      "Epoch 1: 100%|██████████| 79/79 [00:44<00:00,  1.76it/s, loss=24.9, v_num=7, val_loss=26.50, train_loss_step=24.30, train_loss_epoch=24.80]\n",
      "Epoch 2:  39%|███▉      | 31/79 [00:22<00:35,  1.36it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  41%|████      | 32/79 [00:40<00:59,  1.27s/it, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  42%|████▏     | 33/79 [00:40<00:56,  1.24s/it, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  44%|████▍     | 35/79 [00:40<00:51,  1.17s/it, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  47%|████▋     | 37/79 [00:41<00:46,  1.11s/it, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  49%|████▉     | 39/79 [00:41<00:42,  1.06s/it, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  52%|█████▏    | 41/79 [00:41<00:38,  1.01s/it, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  54%|█████▍    | 43/79 [00:41<00:35,  1.03it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  57%|█████▋    | 45/79 [00:42<00:31,  1.07it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  59%|█████▉    | 47/79 [00:42<00:28,  1.11it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  62%|██████▏   | 49/79 [00:42<00:25,  1.15it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  65%|██████▍   | 51/79 [00:42<00:23,  1.20it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  67%|██████▋   | 53/79 [00:42<00:21,  1.23it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  70%|██████▉   | 55/79 [00:43<00:18,  1.28it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  72%|███████▏  | 57/79 [00:43<00:16,  1.32it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  75%|███████▍  | 59/79 [00:43<00:14,  1.36it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  77%|███████▋  | 61/79 [00:43<00:12,  1.40it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  80%|███████▉  | 63/79 [00:43<00:11,  1.44it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  82%|████████▏ | 65/79 [00:43<00:09,  1.48it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  85%|████████▍ | 67/79 [00:44<00:07,  1.52it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  87%|████████▋ | 69/79 [00:44<00:06,  1.56it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  90%|████████▉ | 71/79 [00:44<00:04,  1.60it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  92%|█████████▏| 73/79 [00:44<00:03,  1.64it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  95%|█████████▍| 75/79 [00:44<00:02,  1.68it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2:  97%|█████████▋| 77/79 [00:44<00:01,  1.72it/s, loss=23.1, v_num=7, val_loss=26.50, train_loss_step=20.40, train_loss_epoch=24.80]\n",
      "Epoch 2: 100%|██████████| 79/79 [00:47<00:00,  1.68it/s, loss=23.1, v_num=7, val_loss=26.60, train_loss_step=23.50, train_loss_epoch=23.60]\n",
      "Epoch 3:  39%|███▉      | 31/79 [00:22<00:35,  1.37it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  41%|████      | 32/79 [00:46<01:08,  1.45s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  42%|████▏     | 33/79 [00:46<01:04,  1.41s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  43%|████▎     | 34/79 [00:46<01:01,  1.37s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  44%|████▍     | 35/79 [00:46<00:58,  1.34s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  46%|████▌     | 36/79 [00:46<00:56,  1.30s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  47%|████▋     | 37/79 [00:47<00:53,  1.27s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  48%|████▊     | 38/79 [00:47<00:50,  1.24s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  49%|████▉     | 39/79 [00:47<00:48,  1.21s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  51%|█████     | 40/79 [00:47<00:46,  1.19s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  52%|█████▏    | 41/79 [00:47<00:44,  1.16s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  53%|█████▎    | 42/79 [00:48<00:42,  1.15s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  54%|█████▍    | 43/79 [00:48<00:40,  1.13s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  56%|█████▌    | 44/79 [00:48<00:38,  1.11s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  57%|█████▋    | 45/79 [00:48<00:36,  1.09s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  58%|█████▊    | 46/79 [00:49<00:35,  1.07s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  59%|█████▉    | 47/79 [00:49<00:33,  1.05s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  61%|██████    | 48/79 [00:49<00:31,  1.03s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  62%|██████▏   | 49/79 [00:49<00:30,  1.01s/it, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  63%|██████▎   | 50/79 [00:49<00:28,  1.00it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  65%|██████▍   | 51/79 [00:49<00:27,  1.02it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  66%|██████▌   | 52/79 [00:50<00:26,  1.03it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  67%|██████▋   | 53/79 [00:50<00:24,  1.05it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  70%|██████▉   | 55/79 [00:50<00:22,  1.08it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Validating:  51%|█████     | 25/49 [00:28<00:05,  4.74it/s]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 57/79 [00:51<00:19,  1.11it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Validating:  55%|█████▌    | 27/49 [00:28<00:03,  6.17it/s]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 59/79 [00:51<00:17,  1.15it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Validating:  59%|█████▉    | 29/49 [00:28<00:02,  7.23it/s]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 61/79 [00:51<00:15,  1.18it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Validating:  63%|██████▎   | 31/49 [00:29<00:03,  4.80it/s]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 63/79 [00:52<00:13,  1.21it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  82%|████████▏ | 65/79 [00:52<00:11,  1.24it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  85%|████████▍ | 67/79 [00:52<00:09,  1.27it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  87%|████████▋ | 69/79 [00:52<00:07,  1.31it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  90%|████████▉ | 71/79 [00:52<00:05,  1.34it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  92%|█████████▏| 73/79 [00:53<00:04,  1.37it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  95%|█████████▍| 75/79 [00:53<00:02,  1.41it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3:  97%|█████████▋| 77/79 [00:53<00:01,  1.44it/s, loss=24.8, v_num=7, val_loss=26.60, train_loss_step=22.90, train_loss_epoch=23.60]\n",
      "Epoch 3: 100%|██████████| 79/79 [00:58<00:00,  1.34it/s, loss=24.8, v_num=7, val_loss=26.40, train_loss_step=27.40, train_loss_epoch=24.80]\n",
      "Epoch 4:  39%|███▉      | 31/79 [00:31<00:48,  1.02s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  41%|████      | 32/79 [00:52<01:17,  1.65s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  42%|████▏     | 33/79 [00:53<01:13,  1.61s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  43%|████▎     | 34/79 [00:53<01:10,  1.56s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  46%|████▌     | 36/79 [00:53<01:03,  1.48s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  48%|████▊     | 38/79 [00:53<00:57,  1.41s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  51%|█████     | 40/79 [00:53<00:52,  1.34s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  53%|█████▎    | 42/79 [00:53<00:47,  1.28s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  56%|█████▌    | 44/79 [00:54<00:43,  1.23s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  58%|█████▊    | 46/79 [00:54<00:38,  1.18s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  61%|██████    | 48/79 [00:54<00:35,  1.13s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  63%|██████▎   | 50/79 [00:54<00:31,  1.09s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  66%|██████▌   | 52/79 [00:54<00:28,  1.05s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  68%|██████▊   | 54/79 [00:54<00:25,  1.02s/it, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  71%|███████   | 56/79 [00:55<00:22,  1.02it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  73%|███████▎  | 58/79 [00:55<00:20,  1.05it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  76%|███████▌  | 60/79 [00:55<00:17,  1.08it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  78%|███████▊  | 62/79 [00:55<00:15,  1.11it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  81%|████████  | 64/79 [00:55<00:13,  1.14it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  84%|████████▎ | 66/79 [00:56<00:11,  1.17it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  86%|████████▌ | 68/79 [00:56<00:09,  1.21it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  89%|████████▊ | 70/79 [00:56<00:07,  1.24it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  91%|█████████ | 72/79 [00:56<00:05,  1.27it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Validating:  86%|████████▌ | 42/49 [00:25<00:00,  8.58it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▎| 74/79 [00:57<00:03,  1.30it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  96%|█████████▌| 76/79 [00:57<00:02,  1.33it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4:  99%|█████████▊| 78/79 [00:57<00:00,  1.36it/s, loss=23.1, v_num=7, val_loss=26.40, train_loss_step=26.50, train_loss_epoch=24.80]\n",
      "Epoch 4: 100%|██████████| 79/79 [00:59<00:00,  1.32it/s, loss=23.1, v_num=7, val_loss=26.30, train_loss_step=23.50, train_loss_epoch=23.10]\n",
      "Epoch 5:  39%|███▉      | 31/79 [00:29<00:45,  1.06it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  41%|████      | 32/79 [00:47<01:10,  1.50s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  42%|████▏     | 33/79 [00:48<01:07,  1.46s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  44%|████▍     | 35/79 [00:48<01:00,  1.38s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  47%|████▋     | 37/79 [00:48<00:55,  1.31s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  49%|████▉     | 39/79 [00:48<00:49,  1.25s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  52%|█████▏    | 41/79 [00:48<00:45,  1.19s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  54%|█████▍    | 43/79 [00:49<00:41,  1.14s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  57%|█████▋    | 45/79 [00:49<00:37,  1.10s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  59%|█████▉    | 47/79 [00:49<00:33,  1.05s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  62%|██████▏   | 49/79 [00:49<00:30,  1.01s/it, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  65%|██████▍   | 51/79 [00:49<00:27,  1.02it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  67%|██████▋   | 53/79 [00:50<00:24,  1.06it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  70%|██████▉   | 55/79 [00:50<00:21,  1.09it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  72%|███████▏  | 57/79 [00:50<00:19,  1.13it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  75%|███████▍  | 59/79 [00:50<00:17,  1.17it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  77%|███████▋  | 61/79 [00:50<00:14,  1.20it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  80%|███████▉  | 63/79 [00:51<00:12,  1.23it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  82%|████████▏ | 65/79 [00:51<00:11,  1.27it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  85%|████████▍ | 67/79 [00:51<00:09,  1.31it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  87%|████████▋ | 69/79 [00:51<00:07,  1.34it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  90%|████████▉ | 71/79 [00:51<00:05,  1.38it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  92%|█████████▏| 73/79 [00:52<00:04,  1.39it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  95%|█████████▍| 75/79 [00:52<00:02,  1.43it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5:  97%|█████████▋| 77/79 [00:52<00:01,  1.46it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, loss=23.8, v_num=7, val_loss=26.30, train_loss_step=25.40, train_loss_epoch=23.10]\n",
      "Epoch 5: 100%|██████████| 79/79 [00:54<00:00,  1.44it/s, loss=23.8, v_num=7, val_loss=26.20, train_loss_step=27.10, train_loss_epoch=23.80]\n",
      "Epoch 6:  39%|███▉      | 31/79 [00:31<00:49,  1.02s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  41%|████      | 32/79 [00:53<01:18,  1.67s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  43%|████▎     | 34/79 [00:53<01:11,  1.58s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  46%|████▌     | 36/79 [00:53<01:04,  1.49s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  48%|████▊     | 38/79 [00:53<00:58,  1.42s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  51%|█████     | 40/79 [00:54<00:52,  1.35s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  53%|█████▎    | 42/79 [00:54<00:47,  1.29s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  56%|█████▌    | 44/79 [00:54<00:43,  1.24s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  58%|█████▊    | 46/79 [00:54<00:39,  1.19s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  61%|██████    | 48/79 [00:54<00:35,  1.14s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  63%|██████▎   | 50/79 [00:54<00:31,  1.10s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  66%|██████▌   | 52/79 [00:55<00:28,  1.06s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  68%|██████▊   | 54/79 [00:55<00:25,  1.03s/it, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  71%|███████   | 56/79 [00:55<00:22,  1.01it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  73%|███████▎  | 58/79 [00:55<00:20,  1.04it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  76%|███████▌  | 60/79 [00:55<00:17,  1.08it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  78%|███████▊  | 62/79 [00:56<00:15,  1.10it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  81%|████████  | 64/79 [00:56<00:13,  1.14it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  84%|████████▎ | 66/79 [00:56<00:11,  1.17it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  86%|████████▌ | 68/79 [00:56<00:09,  1.20it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  89%|████████▊ | 70/79 [00:56<00:07,  1.23it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  91%|█████████ | 72/79 [00:56<00:05,  1.26it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  94%|█████████▎| 74/79 [00:57<00:03,  1.30it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  96%|█████████▌| 76/79 [00:57<00:02,  1.33it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6:  99%|█████████▊| 78/79 [00:57<00:00,  1.36it/s, loss=22.6, v_num=7, val_loss=26.20, train_loss_step=20.70, train_loss_epoch=23.80]\n",
      "Epoch 6: 100%|██████████| 79/79 [00:59<00:00,  1.34it/s, loss=22.6, v_num=7, val_loss=26.60, train_loss_step=23.40, train_loss_epoch=23.10]\n",
      "Epoch 7:  39%|███▉      | 31/79 [00:24<00:37,  1.27it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  41%|████      | 32/79 [00:41<01:01,  1.31s/it, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  43%|████▎     | 34/79 [00:41<00:55,  1.23s/it, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  46%|████▌     | 36/79 [00:42<00:50,  1.17s/it, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  48%|████▊     | 38/79 [00:42<00:45,  1.11s/it, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  51%|█████     | 40/79 [00:42<00:41,  1.06s/it, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  53%|█████▎    | 42/79 [00:42<00:37,  1.01s/it, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  56%|█████▌    | 44/79 [00:42<00:33,  1.03it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  58%|█████▊    | 46/79 [00:42<00:30,  1.07it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  61%|██████    | 48/79 [00:42<00:27,  1.12it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  63%|██████▎   | 50/79 [00:43<00:24,  1.16it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  66%|██████▌   | 52/79 [00:43<00:22,  1.20it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  68%|██████▊   | 54/79 [00:43<00:20,  1.24it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  71%|███████   | 56/79 [00:43<00:17,  1.29it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  73%|███████▎  | 58/79 [00:43<00:15,  1.33it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  76%|███████▌  | 60/79 [00:43<00:13,  1.37it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  78%|███████▊  | 62/79 [00:44<00:12,  1.40it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  81%|████████  | 64/79 [00:44<00:10,  1.45it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  84%|████████▎ | 66/79 [00:44<00:08,  1.49it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  86%|████████▌ | 68/79 [00:44<00:07,  1.53it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  89%|████████▊ | 70/79 [00:44<00:05,  1.57it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  91%|█████████ | 72/79 [00:44<00:04,  1.61it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  94%|█████████▎| 74/79 [00:44<00:03,  1.65it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7:  96%|█████████▌| 76/79 [00:45<00:01,  1.69it/s, loss=23.8, v_num=7, val_loss=26.60, train_loss_step=20.90, train_loss_epoch=23.10]\n",
      "Epoch 7: 100%|██████████| 79/79 [00:49<00:00,  1.59it/s, loss=23.8, v_num=7, val_loss=26.20, train_loss_step=22.10, train_loss_epoch=23.60]\n",
      "Epoch 8:  39%|███▉      | 31/79 [00:32<00:49,  1.03s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  41%|████      | 32/79 [00:49<01:13,  1.56s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  43%|████▎     | 34/79 [00:50<01:06,  1.47s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  46%|████▌     | 36/79 [00:50<01:00,  1.40s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  48%|████▊     | 38/79 [00:50<00:54,  1.33s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  51%|█████     | 40/79 [00:50<00:49,  1.27s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  53%|█████▎    | 42/79 [00:51<00:44,  1.21s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  56%|█████▌    | 44/79 [00:51<00:40,  1.16s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  58%|█████▊    | 46/79 [00:51<00:36,  1.11s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  61%|██████    | 48/79 [00:51<00:33,  1.07s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  63%|██████▎   | 50/79 [00:51<00:29,  1.03s/it, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  66%|██████▌   | 52/79 [00:51<00:26,  1.00it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  68%|██████▊   | 54/79 [00:51<00:24,  1.04it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  71%|███████   | 56/79 [00:52<00:21,  1.07it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  73%|███████▎  | 58/79 [00:52<00:18,  1.11it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  76%|███████▌  | 60/79 [00:52<00:16,  1.14it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  78%|███████▊  | 62/79 [00:52<00:14,  1.18it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  81%|████████  | 64/79 [00:52<00:12,  1.21it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  84%|████████▎ | 66/79 [00:52<00:10,  1.25it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  86%|████████▌ | 68/79 [00:52<00:08,  1.28it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  89%|████████▊ | 70/79 [00:53<00:06,  1.32it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  91%|█████████ | 72/79 [00:53<00:05,  1.35it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  94%|█████████▎| 74/79 [00:53<00:03,  1.39it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8:  96%|█████████▌| 76/79 [00:53<00:02,  1.42it/s, loss=22.8, v_num=7, val_loss=26.20, train_loss_step=21.70, train_loss_epoch=23.60]\n",
      "Epoch 8: 100%|██████████| 79/79 [00:55<00:00,  1.43it/s, loss=22.8, v_num=7, val_loss=27.30, train_loss_step=25.90, train_loss_epoch=22.70]\n",
      "Epoch 9:  39%|███▉      | 31/79 [00:30<00:46,  1.03it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  41%|████      | 32/79 [00:50<01:13,  1.57s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  43%|████▎     | 34/79 [00:50<01:06,  1.48s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  46%|████▌     | 36/79 [00:50<01:00,  1.40s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  48%|████▊     | 38/79 [00:50<00:54,  1.33s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  51%|█████     | 40/79 [00:50<00:49,  1.27s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  53%|█████▎    | 42/79 [00:51<00:45,  1.22s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  56%|█████▌    | 44/79 [00:51<00:40,  1.17s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  58%|█████▊    | 46/79 [00:51<00:36,  1.12s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  61%|██████    | 48/79 [00:51<00:33,  1.08s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  63%|██████▎   | 50/79 [00:51<00:30,  1.04s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  66%|██████▌   | 52/79 [00:52<00:27,  1.00s/it, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  68%|██████▊   | 54/79 [00:52<00:24,  1.03it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  71%|███████   | 56/79 [00:52<00:21,  1.07it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  73%|███████▎  | 58/79 [00:52<00:19,  1.10it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  76%|███████▌  | 60/79 [00:52<00:16,  1.14it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  78%|███████▊  | 62/79 [00:53<00:14,  1.17it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  81%|████████  | 64/79 [00:53<00:12,  1.20it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  84%|████████▎ | 66/79 [00:53<00:10,  1.24it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  86%|████████▌ | 68/79 [00:53<00:08,  1.27it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  89%|████████▊ | 70/79 [00:53<00:06,  1.31it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  91%|█████████ | 72/79 [00:53<00:05,  1.34it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  94%|█████████▎| 74/79 [00:53<00:03,  1.37it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  96%|█████████▌| 76/79 [00:54<00:02,  1.41it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9:  99%|█████████▊| 78/79 [00:54<00:00,  1.44it/s, loss=23.2, v_num=7, val_loss=27.30, train_loss_step=27.60, train_loss_epoch=22.70]\n",
      "Epoch 9: 100%|██████████| 79/79 [00:56<00:00,  1.41it/s, loss=23.2, v_num=7, val_loss=28.10, train_loss_step=23.60, train_loss_epoch=23.10]\n",
      "Epoch 10:  39%|███▉      | 31/79 [00:27<00:42,  1.12it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  41%|████      | 32/79 [00:46<01:08,  1.46s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  42%|████▏     | 33/79 [00:46<01:05,  1.42s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  44%|████▍     | 35/79 [00:47<00:59,  1.35s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  47%|████▋     | 37/79 [00:47<00:53,  1.28s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  49%|████▉     | 39/79 [00:47<00:48,  1.22s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  52%|█████▏    | 41/79 [00:47<00:44,  1.16s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  54%|█████▍    | 43/79 [00:47<00:40,  1.11s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  57%|█████▋    | 45/79 [00:48<00:36,  1.07s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  59%|█████▉    | 47/79 [00:48<00:32,  1.03s/it, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  62%|██████▏   | 49/79 [00:48<00:29,  1.01it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  65%|██████▍   | 51/79 [00:48<00:26,  1.05it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  67%|██████▋   | 53/79 [00:49<00:24,  1.07it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  70%|██████▉   | 55/79 [00:49<00:21,  1.10it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  72%|███████▏  | 57/79 [00:49<00:19,  1.14it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  75%|███████▍  | 59/79 [00:50<00:17,  1.18it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  77%|███████▋  | 61/79 [00:50<00:14,  1.21it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  80%|███████▉  | 63/79 [00:50<00:12,  1.24it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  82%|████████▏ | 65/79 [00:50<00:10,  1.28it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  85%|████████▍ | 67/79 [00:50<00:09,  1.32it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  87%|████████▋ | 69/79 [00:51<00:07,  1.35it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  90%|████████▉ | 71/79 [00:51<00:05,  1.39it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  92%|█████████▏| 73/79 [00:51<00:04,  1.42it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  95%|█████████▍| 75/79 [00:51<00:02,  1.46it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10:  97%|█████████▋| 77/79 [00:51<00:01,  1.49it/s, loss=23.4, v_num=7, val_loss=28.10, train_loss_step=20.40, train_loss_epoch=23.10]\n",
      "Epoch 10: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, loss=23.4, v_num=7, val_loss=29.10, train_loss_step=21.70, train_loss_epoch=23.40]\n",
      "Epoch 11:  39%|███▉      | 31/79 [00:26<00:41,  1.16it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  41%|████      | 32/79 [00:45<01:06,  1.41s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  43%|████▎     | 34/79 [00:45<01:00,  1.33s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  46%|████▌     | 36/79 [00:45<00:54,  1.26s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  48%|████▊     | 38/79 [00:45<00:49,  1.20s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  51%|█████     | 40/79 [00:45<00:44,  1.14s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  53%|█████▎    | 42/79 [00:45<00:40,  1.09s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  56%|█████▌    | 44/79 [00:46<00:36,  1.05s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  58%|█████▊    | 46/79 [00:46<00:33,  1.00s/it, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  61%|██████    | 48/79 [00:46<00:29,  1.04it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  63%|██████▎   | 50/79 [00:46<00:26,  1.08it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  66%|██████▌   | 52/79 [00:46<00:24,  1.11it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  68%|██████▊   | 54/79 [00:46<00:21,  1.15it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  71%|███████   | 56/79 [00:46<00:19,  1.19it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  73%|███████▎  | 58/79 [00:47<00:17,  1.23it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  76%|███████▌  | 60/79 [00:47<00:14,  1.27it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  78%|███████▊  | 62/79 [00:47<00:13,  1.31it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  81%|████████  | 64/79 [00:47<00:11,  1.35it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  84%|████████▎ | 66/79 [00:47<00:09,  1.39it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  86%|████████▌ | 68/79 [00:47<00:07,  1.42it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  89%|████████▊ | 70/79 [00:47<00:06,  1.46it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  91%|█████████ | 72/79 [00:48<00:04,  1.50it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  94%|█████████▎| 74/79 [00:48<00:03,  1.54it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  96%|█████████▌| 76/79 [00:48<00:01,  1.57it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11:  99%|█████████▊| 78/79 [00:48<00:00,  1.61it/s, loss=21.5, v_num=7, val_loss=29.10, train_loss_step=22.60, train_loss_epoch=23.40]\n",
      "Epoch 11: 100%|██████████| 79/79 [00:49<00:00,  1.59it/s, loss=21.5, v_num=7, val_loss=26.80, train_loss_step=21.20, train_loss_epoch=21.80]\n",
      "Epoch 12:  39%|███▉      | 31/79 [00:22<00:34,  1.40it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  41%|████      | 32/79 [00:39<00:57,  1.23s/it, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  43%|████▎     | 34/79 [00:39<00:52,  1.16s/it, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  46%|████▌     | 36/79 [00:39<00:47,  1.10s/it, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  48%|████▊     | 38/79 [00:39<00:42,  1.05s/it, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  51%|█████     | 40/79 [00:39<00:38,  1.00it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  53%|█████▎    | 42/79 [00:40<00:35,  1.05it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  56%|█████▌    | 44/79 [00:40<00:32,  1.09it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  58%|█████▊    | 46/79 [00:40<00:28,  1.14it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  61%|██████    | 48/79 [00:40<00:26,  1.19it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  63%|██████▎   | 50/79 [00:40<00:23,  1.23it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  66%|██████▌   | 52/79 [00:40<00:21,  1.27it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  68%|██████▊   | 54/79 [00:40<00:18,  1.32it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  71%|███████   | 56/79 [00:41<00:16,  1.36it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  73%|███████▎  | 58/79 [00:41<00:14,  1.41it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  76%|███████▌  | 60/79 [00:41<00:13,  1.45it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  78%|███████▊  | 62/79 [00:41<00:11,  1.49it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  81%|████████  | 64/79 [00:41<00:09,  1.54it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  84%|████████▎ | 66/79 [00:41<00:08,  1.58it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  86%|████████▌ | 68/79 [00:41<00:06,  1.62it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  89%|████████▊ | 70/79 [00:41<00:05,  1.67it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  91%|█████████ | 72/79 [00:42<00:04,  1.71it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  94%|█████████▎| 74/79 [00:42<00:02,  1.75it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12:  96%|█████████▌| 76/79 [00:42<00:01,  1.79it/s, loss=20.1, v_num=7, val_loss=26.80, train_loss_step=23.30, train_loss_epoch=21.80]\n",
      "Epoch 12: 100%|██████████| 79/79 [00:43<00:00,  1.81it/s, loss=20.1, v_num=7, val_loss=27.10, train_loss_step=19.80, train_loss_epoch=20.30]\n",
      "Epoch 13:  39%|███▉      | 31/79 [00:21<00:33,  1.44it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  41%|████      | 32/79 [00:39<00:57,  1.23s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  43%|████▎     | 34/79 [00:39<00:52,  1.16s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  46%|████▌     | 36/79 [00:39<00:47,  1.10s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  48%|████▊     | 38/79 [00:39<00:42,  1.04s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  51%|█████     | 40/79 [00:39<00:38,  1.00it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  53%|█████▎    | 42/79 [00:40<00:35,  1.05it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  56%|█████▌    | 44/79 [00:40<00:31,  1.10it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  58%|█████▊    | 46/79 [00:40<00:28,  1.14it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  61%|██████    | 48/79 [00:40<00:26,  1.19it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  63%|██████▎   | 50/79 [00:40<00:23,  1.23it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  66%|██████▌   | 52/79 [00:40<00:21,  1.28it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  68%|██████▊   | 54/79 [00:40<00:18,  1.32it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  71%|███████   | 56/79 [00:40<00:16,  1.37it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  73%|███████▎  | 58/79 [00:41<00:14,  1.41it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  76%|███████▌  | 60/79 [00:41<00:13,  1.46it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  78%|███████▊  | 62/79 [00:41<00:11,  1.50it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  81%|████████  | 64/79 [00:41<00:09,  1.54it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  84%|████████▎ | 66/79 [00:41<00:08,  1.59it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  86%|████████▌ | 68/79 [00:41<00:06,  1.63it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  89%|████████▊ | 70/79 [00:41<00:05,  1.67it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  91%|█████████ | 72/79 [00:42<00:04,  1.71it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  94%|█████████▎| 74/79 [00:42<00:02,  1.76it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13:  96%|█████████▌| 76/79 [00:42<00:01,  1.80it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=21.60, train_loss_epoch=20.30]\n",
      "Epoch 13: 100%|██████████| 79/79 [00:44<00:00,  1.78it/s, loss=19.5, v_num=7, val_loss=25.90, train_loss_step=22.50, train_loss_epoch=19.50]\n",
      "Epoch 14:  39%|███▉      | 31/79 [00:22<00:34,  1.38it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  41%|████      | 32/79 [00:39<00:57,  1.23s/it, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  43%|████▎     | 34/79 [00:39<00:52,  1.16s/it, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  46%|████▌     | 36/79 [00:39<00:47,  1.10s/it, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  48%|████▊     | 38/79 [00:39<00:42,  1.04s/it, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  51%|█████     | 40/79 [00:39<00:38,  1.00it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  53%|█████▎    | 42/79 [00:40<00:35,  1.05it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  56%|█████▌    | 44/79 [00:40<00:31,  1.10it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  58%|█████▊    | 46/79 [00:40<00:28,  1.14it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  61%|██████    | 48/79 [00:40<00:26,  1.19it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  63%|██████▎   | 50/79 [00:40<00:23,  1.23it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  66%|██████▌   | 52/79 [00:40<00:21,  1.28it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  68%|██████▊   | 54/79 [00:40<00:18,  1.32it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  71%|███████   | 56/79 [00:40<00:16,  1.37it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  73%|███████▎  | 58/79 [00:41<00:14,  1.41it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  76%|███████▌  | 60/79 [00:41<00:13,  1.46it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  78%|███████▊  | 62/79 [00:41<00:11,  1.50it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  81%|████████  | 64/79 [00:41<00:09,  1.54it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  84%|████████▎ | 66/79 [00:41<00:08,  1.59it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  86%|████████▌ | 68/79 [00:41<00:06,  1.63it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  89%|████████▊ | 70/79 [00:41<00:05,  1.67it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  91%|█████████ | 72/79 [00:42<00:04,  1.71it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  94%|█████████▎| 74/79 [00:42<00:02,  1.76it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14:  96%|█████████▌| 76/79 [00:42<00:01,  1.80it/s, loss=19, v_num=7, val_loss=25.90, train_loss_step=20.30, train_loss_epoch=19.50]\n",
      "Epoch 14: 100%|██████████| 79/79 [00:43<00:00,  1.81it/s, loss=19, v_num=7, val_loss=24.90, train_loss_step=18.10, train_loss_epoch=19.50]\n",
      "Epoch 15:  39%|███▉      | 31/79 [00:25<00:38,  1.24it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  41%|████      | 32/79 [00:46<01:07,  1.44s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  43%|████▎     | 34/79 [00:46<01:01,  1.36s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  46%|████▌     | 36/79 [00:46<00:55,  1.29s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  48%|████▊     | 38/79 [00:46<00:50,  1.23s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  51%|█████     | 40/79 [00:46<00:45,  1.17s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  53%|█████▎    | 42/79 [00:47<00:41,  1.12s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  56%|█████▌    | 44/79 [00:47<00:37,  1.08s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  58%|█████▊    | 46/79 [00:47<00:34,  1.03s/it, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  61%|██████    | 48/79 [00:47<00:30,  1.01it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  63%|██████▎   | 50/79 [00:47<00:27,  1.04it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  66%|██████▌   | 52/79 [00:48<00:25,  1.08it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  68%|██████▊   | 54/79 [00:48<00:22,  1.12it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  71%|███████   | 56/79 [00:48<00:19,  1.15it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  73%|███████▎  | 58/79 [00:48<00:17,  1.19it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  76%|███████▌  | 60/79 [00:48<00:15,  1.23it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  78%|███████▊  | 62/79 [00:49<00:13,  1.26it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  81%|████████  | 64/79 [00:49<00:11,  1.30it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  84%|████████▎ | 66/79 [00:49<00:09,  1.33it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  86%|████████▌ | 68/79 [00:49<00:08,  1.37it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  89%|████████▊ | 70/79 [00:49<00:06,  1.41it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  91%|█████████ | 72/79 [00:49<00:04,  1.44it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  94%|█████████▎| 74/79 [00:50<00:03,  1.48it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  96%|█████████▌| 76/79 [00:50<00:01,  1.51it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15:  99%|█████████▊| 78/79 [00:50<00:00,  1.55it/s, loss=18.8, v_num=7, val_loss=24.90, train_loss_step=17.20, train_loss_epoch=19.50]\n",
      "Epoch 15: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, loss=18.8, v_num=7, val_loss=23.70, train_loss_step=21.30, train_loss_epoch=18.80]\n",
      "Epoch 16:  39%|███▉      | 31/79 [00:30<00:46,  1.03it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  41%|████      | 32/79 [00:48<01:10,  1.50s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  42%|████▏     | 33/79 [00:48<01:07,  1.46s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  43%|████▎     | 34/79 [00:48<01:03,  1.42s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  46%|████▌     | 36/79 [00:48<00:57,  1.35s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  48%|████▊     | 38/79 [00:48<00:52,  1.28s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  51%|█████     | 40/79 [00:48<00:47,  1.22s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  53%|█████▎    | 42/79 [00:49<00:43,  1.17s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  56%|█████▌    | 44/79 [00:49<00:39,  1.12s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  58%|█████▊    | 46/79 [00:49<00:35,  1.07s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  61%|██████    | 48/79 [00:49<00:31,  1.03s/it, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  63%|██████▎   | 50/79 [00:49<00:28,  1.01it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  66%|██████▌   | 52/79 [00:49<00:25,  1.04it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  68%|██████▊   | 54/79 [00:50<00:23,  1.08it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  71%|███████   | 56/79 [00:50<00:20,  1.11it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  73%|███████▎  | 58/79 [00:50<00:18,  1.15it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  76%|███████▌  | 60/79 [00:50<00:16,  1.19it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  78%|███████▊  | 62/79 [00:50<00:13,  1.22it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  81%|████████  | 64/79 [00:51<00:11,  1.25it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  84%|████████▎ | 66/79 [00:51<00:10,  1.29it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  86%|████████▌ | 68/79 [00:51<00:08,  1.33it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  89%|████████▊ | 70/79 [00:51<00:06,  1.36it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  91%|█████████ | 72/79 [00:51<00:05,  1.39it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  94%|█████████▎| 74/79 [00:51<00:03,  1.43it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  96%|█████████▌| 76/79 [00:51<00:02,  1.47it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16:  99%|█████████▊| 78/79 [00:51<00:00,  1.50it/s, loss=18.2, v_num=7, val_loss=23.70, train_loss_step=17.80, train_loss_epoch=18.80]\n",
      "Epoch 16: 100%|██████████| 79/79 [00:53<00:00,  1.48it/s, loss=18.2, v_num=7, val_loss=24.10, train_loss_step=16.20, train_loss_epoch=18.30]\n",
      "Epoch 17:  39%|███▉      | 31/79 [00:25<00:39,  1.21it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  41%|████      | 32/79 [00:43<01:04,  1.37s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  42%|████▏     | 33/79 [00:43<01:01,  1.33s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  43%|████▎     | 34/79 [00:44<00:58,  1.29s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  46%|████▌     | 36/79 [00:44<00:52,  1.23s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  48%|████▊     | 38/79 [00:44<00:47,  1.17s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  51%|█████     | 40/79 [00:44<00:43,  1.11s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  53%|█████▎    | 42/79 [00:44<00:39,  1.06s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  56%|█████▌    | 44/79 [00:44<00:35,  1.02s/it, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  58%|█████▊    | 46/79 [00:44<00:32,  1.02it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  61%|██████    | 48/79 [00:45<00:29,  1.06it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  63%|██████▎   | 50/79 [00:45<00:26,  1.10it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  66%|██████▌   | 52/79 [00:45<00:23,  1.14it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  68%|██████▊   | 54/79 [00:45<00:21,  1.18it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  71%|███████   | 56/79 [00:45<00:18,  1.22it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  73%|███████▎  | 58/79 [00:45<00:16,  1.26it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  76%|███████▌  | 60/79 [00:46<00:14,  1.30it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  78%|███████▊  | 62/79 [00:46<00:12,  1.34it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  81%|████████  | 64/79 [00:46<00:10,  1.38it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  84%|████████▎ | 66/79 [00:46<00:09,  1.42it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  86%|████████▌ | 68/79 [00:46<00:07,  1.46it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  89%|████████▊ | 70/79 [00:46<00:06,  1.49it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  91%|█████████ | 72/79 [00:47<00:04,  1.53it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  94%|█████████▎| 74/79 [00:47<00:03,  1.57it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  96%|█████████▌| 76/79 [00:47<00:01,  1.61it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17:  99%|█████████▊| 78/79 [00:47<00:00,  1.65it/s, loss=17.8, v_num=7, val_loss=24.10, train_loss_step=18.40, train_loss_epoch=18.30]\n",
      "Epoch 17: 100%|██████████| 79/79 [00:49<00:00,  1.59it/s, loss=17.8, v_num=7, val_loss=23.20, train_loss_step=18.40, train_loss_epoch=17.90]\n",
      "Epoch 18:  39%|███▉      | 31/79 [00:23<00:36,  1.32it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  41%|████      | 32/79 [00:41<01:00,  1.29s/it, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  42%|████▏     | 33/79 [00:41<00:57,  1.25s/it, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  44%|████▍     | 35/79 [00:41<00:52,  1.19s/it, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  47%|████▋     | 37/79 [00:41<00:47,  1.13s/it, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  49%|████▉     | 39/79 [00:41<00:42,  1.07s/it, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  52%|█████▏    | 41/79 [00:42<00:38,  1.02s/it, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  54%|█████▍    | 43/79 [00:42<00:35,  1.02it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  57%|█████▋    | 45/79 [00:42<00:32,  1.06it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  59%|█████▉    | 47/79 [00:42<00:28,  1.10it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  62%|██████▏   | 49/79 [00:42<00:26,  1.15it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  65%|██████▍   | 51/79 [00:42<00:23,  1.19it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  67%|██████▋   | 53/79 [00:43<00:21,  1.23it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  70%|██████▉   | 55/79 [00:43<00:18,  1.27it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  72%|███████▏  | 57/79 [00:43<00:16,  1.31it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  75%|███████▍  | 59/79 [00:43<00:14,  1.36it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  77%|███████▋  | 61/79 [00:43<00:12,  1.40it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  80%|███████▉  | 63/79 [00:43<00:11,  1.43it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  82%|████████▏ | 65/79 [00:44<00:09,  1.48it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  85%|████████▍ | 67/79 [00:44<00:07,  1.52it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  87%|████████▋ | 69/79 [00:44<00:06,  1.56it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  90%|████████▉ | 71/79 [00:44<00:05,  1.60it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  92%|█████████▏| 73/79 [00:44<00:03,  1.64it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  95%|█████████▍| 75/79 [00:44<00:02,  1.68it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18:  97%|█████████▋| 77/79 [00:44<00:01,  1.72it/s, loss=17.6, v_num=7, val_loss=23.20, train_loss_step=16.10, train_loss_epoch=17.90]\n",
      "Epoch 18: 100%|██████████| 79/79 [00:46<00:00,  1.70it/s, loss=17.6, v_num=7, val_loss=23.40, train_loss_step=16.90, train_loss_epoch=17.60]\n",
      "Epoch 19:  39%|███▉      | 31/79 [00:24<00:37,  1.27it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  41%|████      | 32/79 [00:42<01:03,  1.34s/it, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  42%|████▏     | 33/79 [00:43<01:00,  1.31s/it, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  44%|████▍     | 35/79 [00:43<00:54,  1.23s/it, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  47%|████▋     | 37/79 [00:43<00:49,  1.17s/it, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  49%|████▉     | 39/79 [00:43<00:44,  1.12s/it, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  52%|█████▏    | 41/79 [00:43<00:40,  1.06s/it, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  54%|█████▍    | 43/79 [00:43<00:36,  1.02s/it, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  57%|█████▋    | 45/79 [00:44<00:33,  1.02it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  59%|█████▉    | 47/79 [00:44<00:30,  1.06it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  62%|██████▏   | 49/79 [00:44<00:27,  1.11it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  65%|██████▍   | 51/79 [00:44<00:24,  1.15it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  67%|██████▋   | 53/79 [00:44<00:21,  1.19it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  70%|██████▉   | 55/79 [00:44<00:19,  1.23it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  72%|███████▏  | 57/79 [00:44<00:17,  1.27it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  75%|███████▍  | 59/79 [00:45<00:15,  1.31it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  77%|███████▋  | 61/79 [00:45<00:13,  1.35it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  80%|███████▉  | 63/79 [00:45<00:11,  1.38it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  82%|████████▏ | 65/79 [00:45<00:09,  1.42it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  85%|████████▍ | 67/79 [00:45<00:08,  1.46it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  87%|████████▋ | 69/79 [00:45<00:06,  1.50it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  90%|████████▉ | 71/79 [00:45<00:05,  1.54it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  92%|█████████▏| 73/79 [00:46<00:03,  1.58it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  95%|█████████▍| 75/79 [00:46<00:02,  1.62it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19:  97%|█████████▋| 77/79 [00:46<00:01,  1.66it/s, loss=17.1, v_num=7, val_loss=23.40, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Epoch 19: 100%|██████████| 79/79 [00:48<00:00,  1.64it/s, loss=17.1, v_num=7, val_loss=23.10, train_loss_step=16.80, train_loss_epoch=17.20]\n",
      "Epoch 20:  39%|███▉      | 31/79 [00:29<00:45,  1.07it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  41%|████      | 32/79 [00:46<01:08,  1.45s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  42%|████▏     | 33/79 [00:46<01:04,  1.41s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  44%|████▍     | 35/79 [00:46<00:58,  1.34s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  47%|████▋     | 37/79 [00:46<00:53,  1.27s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  49%|████▉     | 39/79 [00:47<00:48,  1.21s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  52%|█████▏    | 41/79 [00:47<00:43,  1.16s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  54%|█████▍    | 43/79 [00:47<00:39,  1.11s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  57%|█████▋    | 45/79 [00:47<00:36,  1.06s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  59%|█████▉    | 47/79 [00:47<00:32,  1.02s/it, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  62%|██████▏   | 49/79 [00:48<00:29,  1.02it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  65%|██████▍   | 51/79 [00:48<00:26,  1.06it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  67%|██████▋   | 53/79 [00:48<00:23,  1.09it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  70%|██████▉   | 55/79 [00:48<00:21,  1.13it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  72%|███████▏  | 57/79 [00:48<00:18,  1.17it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  75%|███████▍  | 59/79 [00:49<00:16,  1.20it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  77%|███████▋  | 61/79 [00:49<00:14,  1.24it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  80%|███████▉  | 63/79 [00:49<00:12,  1.27it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  82%|████████▏ | 65/79 [00:49<00:10,  1.31it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  85%|████████▍ | 67/79 [00:49<00:08,  1.35it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  87%|████████▋ | 69/79 [00:49<00:07,  1.38it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  90%|████████▉ | 71/79 [00:50<00:05,  1.42it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  92%|█████████▏| 73/79 [00:50<00:04,  1.45it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  95%|█████████▍| 75/79 [00:50<00:02,  1.49it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20:  97%|█████████▋| 77/79 [00:50<00:01,  1.52it/s, loss=17, v_num=7, val_loss=23.10, train_loss_step=20.70, train_loss_epoch=17.20]\n",
      "Epoch 20: 100%|██████████| 79/79 [00:52<00:00,  1.50it/s, loss=17, v_num=7, val_loss=23.80, train_loss_step=16.20, train_loss_epoch=17.10]\n",
      "Epoch 21:  39%|███▉      | 31/79 [00:27<00:41,  1.15it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  41%|████      | 32/79 [00:45<01:06,  1.42s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  42%|████▏     | 33/79 [00:45<01:03,  1.38s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  44%|████▍     | 35/79 [00:45<00:57,  1.30s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  47%|████▋     | 37/79 [00:45<00:51,  1.24s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  49%|████▉     | 39/79 [00:45<00:47,  1.18s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  52%|█████▏    | 41/79 [00:46<00:42,  1.12s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  54%|█████▍    | 43/79 [00:46<00:38,  1.08s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  57%|█████▋    | 45/79 [00:46<00:35,  1.03s/it, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  59%|█████▉    | 47/79 [00:46<00:31,  1.01it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  62%|██████▏   | 49/79 [00:46<00:28,  1.04it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  65%|██████▍   | 51/79 [00:47<00:25,  1.08it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  67%|██████▋   | 53/79 [00:47<00:23,  1.12it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  70%|██████▉   | 55/79 [00:47<00:20,  1.15it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Validating:  51%|█████     | 25/49 [00:20<00:03,  6.42it/s]\u001b[A\n",
      "Epoch 21:  72%|███████▏  | 57/79 [00:48<00:18,  1.19it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  75%|███████▍  | 59/79 [00:48<00:16,  1.22it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Validating:  59%|█████▉    | 29/49 [00:21<00:03,  6.31it/s]\u001b[A\n",
      "Epoch 21:  77%|███████▋  | 61/79 [00:48<00:14,  1.25it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Validating:  63%|██████▎   | 31/49 [00:22<00:05,  3.55it/s]\u001b[A\n",
      "Epoch 21:  80%|███████▉  | 63/79 [00:49<00:12,  1.27it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Validating:  67%|██████▋   | 33/49 [00:22<00:04,  3.86it/s]\u001b[A\n",
      "Epoch 21:  82%|████████▏ | 65/79 [00:49<00:10,  1.30it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  85%|████████▍ | 67/79 [00:50<00:08,  1.34it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  87%|████████▋ | 69/79 [00:50<00:07,  1.37it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  90%|████████▉ | 71/79 [00:50<00:05,  1.41it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Validating:  84%|████████▎ | 41/49 [00:23<00:01,  6.79it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 73/79 [00:50<00:04,  1.44it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  95%|█████████▍| 75/79 [00:51<00:02,  1.47it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21:  97%|█████████▋| 77/79 [00:51<00:01,  1.50it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, loss=16.8, v_num=7, val_loss=23.80, train_loss_step=17.40, train_loss_epoch=17.10]\n",
      "Epoch 21: 100%|██████████| 79/79 [00:54<00:00,  1.46it/s, loss=16.8, v_num=7, val_loss=24.10, train_loss_step=16.60, train_loss_epoch=17.10]\n",
      "Epoch 22:  39%|███▉      | 31/79 [00:32<00:50,  1.06s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  41%|████      | 32/79 [00:53<01:18,  1.67s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  42%|████▏     | 33/79 [00:53<01:14,  1.62s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  43%|████▎     | 34/79 [00:53<01:10,  1.58s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  44%|████▍     | 35/79 [00:53<01:07,  1.53s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  47%|████▋     | 37/79 [00:53<01:01,  1.46s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  49%|████▉     | 39/79 [00:54<00:55,  1.39s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  52%|█████▏    | 41/79 [00:54<00:50,  1.32s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  54%|█████▍    | 43/79 [00:54<00:45,  1.27s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  57%|█████▋    | 45/79 [00:54<00:41,  1.22s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  59%|█████▉    | 47/79 [00:54<00:37,  1.17s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  62%|██████▏   | 49/79 [00:55<00:33,  1.12s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  65%|██████▍   | 51/79 [00:55<00:30,  1.08s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  67%|██████▋   | 53/79 [00:55<00:27,  1.05s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Validating:  47%|████▋     | 23/49 [00:22<00:03,  6.74it/s]\u001b[A\n",
      "Epoch 22:  70%|██████▉   | 55/79 [00:55<00:24,  1.01s/it, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  72%|███████▏  | 57/79 [00:55<00:21,  1.02it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  75%|███████▍  | 59/79 [00:56<00:19,  1.05it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  77%|███████▋  | 61/79 [00:56<00:16,  1.08it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  80%|███████▉  | 63/79 [00:56<00:14,  1.11it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  82%|████████▏ | 65/79 [00:56<00:12,  1.14it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  85%|████████▍ | 67/79 [00:56<00:10,  1.18it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  87%|████████▋ | 69/79 [00:57<00:08,  1.21it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  90%|████████▉ | 71/79 [00:57<00:06,  1.24it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Validating:  84%|████████▎ | 41/49 [00:26<00:02,  2.86it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 73/79 [00:59<00:04,  1.23it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  95%|█████████▍| 75/79 [00:59<00:03,  1.26it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22:  97%|█████████▋| 77/79 [00:59<00:01,  1.29it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22: 100%|██████████| 79/79 [00:59<00:00,  1.32it/s, loss=17.4, v_num=7, val_loss=24.10, train_loss_step=15.00, train_loss_epoch=17.10]\n",
      "Epoch 22: 100%|██████████| 79/79 [01:02<00:00,  1.27it/s, loss=17.4, v_num=7, val_loss=23.90, train_loss_step=20.70, train_loss_epoch=17.40]\n",
      "Epoch 23:  39%|███▉      | 31/79 [00:30<00:47,  1.01it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  41%|████      | 32/79 [00:52<01:16,  1.63s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  42%|████▏     | 33/79 [00:52<01:12,  1.58s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  44%|████▍     | 35/79 [00:52<01:05,  1.50s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  47%|████▋     | 37/79 [00:52<00:59,  1.42s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  49%|████▉     | 39/79 [00:52<00:54,  1.35s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  52%|█████▏    | 41/79 [00:52<00:49,  1.29s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  54%|█████▍    | 43/79 [00:53<00:44,  1.24s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  57%|█████▋    | 45/79 [00:53<00:40,  1.19s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Validating:  31%|███       | 15/49 [00:22<00:11,  2.96it/s]\u001b[A\n",
      "Epoch 23:  59%|█████▉    | 47/79 [00:53<00:36,  1.14s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Validating:  35%|███▍      | 17/49 [00:22<00:07,  4.02it/s]\u001b[A\n",
      "Epoch 23:  62%|██████▏   | 49/79 [00:54<00:33,  1.10s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Validating:  39%|███▉      | 19/49 [00:23<00:06,  4.43it/s]\u001b[A\n",
      "Epoch 23:  65%|██████▍   | 51/79 [00:54<00:29,  1.06s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Validating:  43%|████▎     | 21/49 [00:23<00:05,  4.85it/s]\u001b[A\n",
      "Epoch 23:  67%|██████▋   | 53/79 [00:54<00:26,  1.03s/it, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  70%|██████▉   | 55/79 [00:54<00:23,  1.00it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  72%|███████▏  | 57/79 [00:55<00:21,  1.04it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Validating:  55%|█████▌    | 27/49 [00:24<00:02,  8.25it/s]\u001b[A\n",
      "Epoch 23:  75%|███████▍  | 59/79 [00:55<00:18,  1.07it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  77%|███████▋  | 61/79 [00:55<00:16,  1.10it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  80%|███████▉  | 63/79 [00:55<00:14,  1.13it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  82%|████████▏ | 65/79 [00:55<00:12,  1.16it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  85%|████████▍ | 67/79 [00:55<00:10,  1.20it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  87%|████████▋ | 69/79 [00:56<00:08,  1.23it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  90%|████████▉ | 71/79 [00:56<00:06,  1.26it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  92%|█████████▏| 73/79 [00:56<00:04,  1.29it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  95%|█████████▍| 75/79 [00:56<00:03,  1.33it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23:  97%|█████████▋| 77/79 [00:56<00:01,  1.36it/s, loss=19.3, v_num=7, val_loss=23.90, train_loss_step=20.80, train_loss_epoch=17.40]\n",
      "Epoch 23: 100%|██████████| 79/79 [00:58<00:00,  1.35it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=22.00, train_loss_epoch=18.70]\n",
      "Epoch 24:  39%|███▉      | 31/79 [00:27<00:42,  1.13it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  41%|████      | 32/79 [00:47<01:09,  1.48s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  42%|████▏     | 33/79 [00:47<01:06,  1.44s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  44%|████▍     | 35/79 [00:47<00:59,  1.36s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  47%|████▋     | 37/79 [00:47<00:54,  1.29s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  49%|████▉     | 39/79 [00:47<00:49,  1.23s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  52%|█████▏    | 41/79 [00:47<00:44,  1.17s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  54%|█████▍    | 43/79 [00:48<00:40,  1.12s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  57%|█████▋    | 45/79 [00:48<00:36,  1.08s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  59%|█████▉    | 47/79 [00:48<00:33,  1.03s/it, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  62%|██████▏   | 49/79 [00:48<00:29,  1.01it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  65%|██████▍   | 51/79 [00:48<00:26,  1.04it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  67%|██████▋   | 53/79 [00:49<00:24,  1.08it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  70%|██████▉   | 55/79 [00:49<00:21,  1.12it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  72%|███████▏  | 57/79 [00:49<00:19,  1.15it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  75%|███████▍  | 59/79 [00:49<00:16,  1.19it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  77%|███████▋  | 61/79 [00:49<00:14,  1.23it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  80%|███████▉  | 63/79 [00:50<00:12,  1.26it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  82%|████████▏ | 65/79 [00:50<00:10,  1.30it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  85%|████████▍ | 67/79 [00:50<00:09,  1.33it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  87%|████████▋ | 69/79 [00:50<00:07,  1.37it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  90%|████████▉ | 71/79 [00:50<00:05,  1.41it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  92%|█████████▏| 73/79 [00:50<00:04,  1.44it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  95%|█████████▍| 75/79 [00:50<00:02,  1.47it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24:  97%|█████████▋| 77/79 [00:51<00:01,  1.51it/s, loss=19.3, v_num=7, val_loss=28.40, train_loss_step=16.70, train_loss_epoch=18.70]\n",
      "Epoch 24: 100%|██████████| 79/79 [00:53<00:00,  1.49it/s, loss=19.3, v_num=7, val_loss=25.10, train_loss_step=18.00, train_loss_epoch=20.00]\n",
      "Epoch 25:  39%|███▉      | 31/79 [00:27<00:41,  1.15it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  41%|████      | 32/79 [00:46<01:08,  1.45s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  42%|████▏     | 33/79 [00:46<01:04,  1.41s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  44%|████▍     | 35/79 [00:46<00:58,  1.34s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  47%|████▋     | 37/79 [00:46<00:53,  1.27s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  49%|████▉     | 39/79 [00:47<00:48,  1.21s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  52%|█████▏    | 41/79 [00:47<00:43,  1.15s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  54%|█████▍    | 43/79 [00:47<00:39,  1.11s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  57%|█████▋    | 45/79 [00:47<00:36,  1.06s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  59%|█████▉    | 47/79 [00:47<00:32,  1.02s/it, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  62%|██████▏   | 49/79 [00:48<00:29,  1.02it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  65%|██████▍   | 51/79 [00:48<00:26,  1.06it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  67%|██████▋   | 53/79 [00:48<00:23,  1.09it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  70%|██████▉   | 55/79 [00:48<00:21,  1.13it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  72%|███████▏  | 57/79 [00:48<00:18,  1.17it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  75%|███████▍  | 59/79 [00:48<00:16,  1.21it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  77%|███████▋  | 61/79 [00:49<00:14,  1.24it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  80%|███████▉  | 63/79 [00:49<00:12,  1.28it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  82%|████████▏ | 65/79 [00:49<00:10,  1.31it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  85%|████████▍ | 67/79 [00:49<00:08,  1.35it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  87%|████████▋ | 69/79 [00:49<00:07,  1.39it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  90%|████████▉ | 71/79 [00:49<00:05,  1.42it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  92%|█████████▏| 73/79 [00:50<00:04,  1.46it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  95%|█████████▍| 75/79 [00:50<00:02,  1.49it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25:  97%|█████████▋| 77/79 [00:50<00:01,  1.53it/s, loss=17.7, v_num=7, val_loss=25.10, train_loss_step=18.50, train_loss_epoch=20.00]\n",
      "Epoch 25: 100%|██████████| 79/79 [00:52<00:00,  1.51it/s, loss=17.7, v_num=7, val_loss=25.40, train_loss_step=15.60, train_loss_epoch=17.70]\n",
      "Epoch 26:  39%|███▉      | 31/79 [00:26<00:41,  1.15it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  41%|████      | 32/79 [00:45<01:07,  1.43s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  42%|████▏     | 33/79 [00:45<01:04,  1.39s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  44%|████▍     | 35/79 [00:46<00:58,  1.32s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  47%|████▋     | 37/79 [00:46<00:52,  1.25s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  49%|████▉     | 39/79 [00:46<00:47,  1.19s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  52%|█████▏    | 41/79 [00:46<00:43,  1.14s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  54%|█████▍    | 43/79 [00:46<00:39,  1.09s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  57%|█████▋    | 45/79 [00:47<00:35,  1.05s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  59%|█████▉    | 47/79 [00:47<00:32,  1.00s/it, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  62%|██████▏   | 49/79 [00:47<00:29,  1.03it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  65%|██████▍   | 51/79 [00:47<00:26,  1.07it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  67%|██████▋   | 53/79 [00:47<00:23,  1.11it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  70%|██████▉   | 55/79 [00:47<00:20,  1.15it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  72%|███████▏  | 57/79 [00:48<00:18,  1.18it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  75%|███████▍  | 59/79 [00:48<00:16,  1.22it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  77%|███████▋  | 61/79 [00:48<00:14,  1.26it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  80%|███████▉  | 63/79 [00:48<00:12,  1.29it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  82%|████████▏ | 65/79 [00:48<00:10,  1.33it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  85%|████████▍ | 67/79 [00:49<00:08,  1.36it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  87%|████████▋ | 69/79 [00:49<00:07,  1.40it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  90%|████████▉ | 71/79 [00:49<00:05,  1.44it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  92%|█████████▏| 73/79 [00:49<00:04,  1.47it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  95%|█████████▍| 75/79 [00:49<00:02,  1.51it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26:  97%|█████████▋| 77/79 [00:49<00:01,  1.54it/s, loss=17.2, v_num=7, val_loss=25.40, train_loss_step=16.00, train_loss_epoch=17.70]\n",
      "Epoch 26: 100%|██████████| 79/79 [00:51<00:00,  1.53it/s, loss=17.2, v_num=7, val_loss=25.80, train_loss_step=15.10, train_loss_epoch=17.00]\n",
      "Epoch 27:  39%|███▉      | 31/79 [00:27<00:42,  1.12it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  41%|████      | 32/79 [00:47<01:09,  1.47s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  42%|████▏     | 33/79 [00:47<01:05,  1.43s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  44%|████▍     | 35/79 [00:47<00:59,  1.35s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  47%|████▋     | 37/79 [00:47<00:53,  1.28s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  49%|████▉     | 39/79 [00:47<00:48,  1.22s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  52%|█████▏    | 41/79 [00:47<00:44,  1.17s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  54%|█████▍    | 43/79 [00:48<00:40,  1.12s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  57%|█████▋    | 45/79 [00:48<00:36,  1.07s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  59%|█████▉    | 47/79 [00:48<00:32,  1.03s/it, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  62%|██████▏   | 49/79 [00:48<00:29,  1.01it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  65%|██████▍   | 51/79 [00:48<00:26,  1.05it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  67%|██████▋   | 53/79 [00:49<00:24,  1.08it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  70%|██████▉   | 55/79 [00:49<00:21,  1.12it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  72%|███████▏  | 57/79 [00:49<00:19,  1.15it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  75%|███████▍  | 59/79 [00:49<00:16,  1.19it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  77%|███████▋  | 61/79 [00:49<00:14,  1.23it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  80%|███████▉  | 63/79 [00:49<00:12,  1.26it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  82%|████████▏ | 65/79 [00:50<00:10,  1.30it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  85%|████████▍ | 67/79 [00:50<00:09,  1.33it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  87%|████████▋ | 69/79 [00:50<00:07,  1.37it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  90%|████████▉ | 71/79 [00:50<00:05,  1.40it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  92%|█████████▏| 73/79 [00:50<00:04,  1.44it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  95%|█████████▍| 75/79 [00:50<00:02,  1.47it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27:  97%|█████████▋| 77/79 [00:51<00:01,  1.51it/s, loss=18.3, v_num=7, val_loss=25.80, train_loss_step=22.70, train_loss_epoch=17.00]\n",
      "Epoch 27: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, loss=18.3, v_num=7, val_loss=26.50, train_loss_step=19.10, train_loss_epoch=17.90]\n",
      "Epoch 28:  39%|███▉      | 31/79 [00:26<00:40,  1.19it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  41%|████      | 32/79 [00:46<01:08,  1.46s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  42%|████▏     | 33/79 [00:46<01:05,  1.42s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  43%|████▎     | 34/79 [00:46<01:02,  1.38s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  44%|████▍     | 35/79 [00:46<00:59,  1.34s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  47%|████▋     | 37/79 [00:47<00:53,  1.27s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  49%|████▉     | 39/79 [00:47<00:48,  1.21s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  52%|█████▏    | 41/79 [00:47<00:44,  1.16s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  54%|█████▍    | 43/79 [00:47<00:39,  1.11s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  57%|█████▋    | 45/79 [00:47<00:36,  1.07s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  59%|█████▉    | 47/79 [00:48<00:32,  1.02s/it, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  62%|██████▏   | 49/79 [00:48<00:29,  1.02it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  65%|██████▍   | 51/79 [00:48<00:26,  1.05it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  67%|██████▋   | 53/79 [00:48<00:23,  1.09it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  70%|██████▉   | 55/79 [00:48<00:21,  1.13it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  72%|███████▏  | 57/79 [00:48<00:18,  1.16it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  75%|███████▍  | 59/79 [00:49<00:16,  1.20it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  77%|███████▋  | 61/79 [00:49<00:14,  1.24it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Validating:  63%|██████▎   | 31/49 [00:25<00:07,  2.35it/s]\u001b[A\n",
      "Epoch 28:  80%|███████▉  | 63/79 [00:51<00:13,  1.22it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  82%|████████▏ | 65/79 [00:52<00:11,  1.25it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  85%|████████▍ | 67/79 [00:52<00:09,  1.29it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  87%|████████▋ | 69/79 [00:52<00:07,  1.32it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  90%|████████▉ | 71/79 [00:52<00:05,  1.36it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  92%|█████████▏| 73/79 [00:52<00:04,  1.39it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  95%|█████████▍| 75/79 [00:52<00:02,  1.42it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28:  97%|█████████▋| 77/79 [00:52<00:01,  1.46it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28: 100%|██████████| 79/79 [00:52<00:00,  1.49it/s, loss=18.1, v_num=7, val_loss=26.50, train_loss_step=19.60, train_loss_epoch=17.90]\n",
      "Epoch 28: 100%|██████████| 79/79 [00:54<00:00,  1.44it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.20, train_loss_epoch=18.20]\n",
      "Epoch 29:  39%|███▉      | 31/79 [00:25<00:39,  1.21it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  41%|████      | 32/79 [00:43<01:04,  1.37s/it, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  42%|████▏     | 33/79 [00:43<01:01,  1.33s/it, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  44%|████▍     | 35/79 [00:44<00:55,  1.26s/it, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  47%|████▋     | 37/79 [00:44<00:50,  1.19s/it, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  49%|████▉     | 39/79 [00:44<00:45,  1.14s/it, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  52%|█████▏    | 41/79 [00:44<00:41,  1.09s/it, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  54%|█████▍    | 43/79 [00:44<00:37,  1.04s/it, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  57%|█████▋    | 45/79 [00:44<00:33,  1.00it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  59%|█████▉    | 47/79 [00:45<00:30,  1.04it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  62%|██████▏   | 49/79 [00:45<00:27,  1.08it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  65%|██████▍   | 51/79 [00:45<00:24,  1.12it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  67%|██████▋   | 53/79 [00:45<00:22,  1.16it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  70%|██████▉   | 55/79 [00:45<00:19,  1.20it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  72%|███████▏  | 57/79 [00:45<00:17,  1.24it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  75%|███████▍  | 59/79 [00:46<00:15,  1.28it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  77%|███████▋  | 61/79 [00:46<00:13,  1.32it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  80%|███████▉  | 63/79 [00:46<00:11,  1.36it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  82%|████████▏ | 65/79 [00:46<00:10,  1.39it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:  85%|████████▍ | 67/79 [00:46<00:08,  1.43it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  87%|████████▋ | 69/79 [00:46<00:06,  1.47it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  90%|████████▉ | 71/79 [00:46<00:05,  1.51it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  92%|█████████▏| 73/79 [00:47<00:03,  1.55it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  95%|█████████▍| 75/79 [00:47<00:02,  1.59it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29:  97%|█████████▋| 77/79 [00:47<00:01,  1.62it/s, loss=18.1, v_num=7, val_loss=27.30, train_loss_step=18.60, train_loss_epoch=18.20]\n",
      "Epoch 29: 100%|██████████| 79/79 [00:49<00:00,  1.60it/s, loss=18.1, v_num=7, val_loss=26.80, train_loss_step=17.50, train_loss_epoch=18.10]\n",
      "Epoch 30:  39%|███▉      | 31/79 [00:24<00:37,  1.29it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  41%|████      | 32/79 [00:43<01:03,  1.35s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  42%|████▏     | 33/79 [00:43<01:00,  1.32s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  43%|████▎     | 34/79 [00:43<00:57,  1.28s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  46%|████▌     | 36/79 [00:43<00:52,  1.22s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  48%|████▊     | 38/79 [00:43<00:47,  1.16s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  51%|█████     | 40/79 [00:44<00:42,  1.10s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  53%|█████▎    | 42/79 [00:44<00:39,  1.06s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  56%|█████▌    | 44/79 [00:44<00:35,  1.01s/it, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  58%|█████▊    | 46/79 [00:44<00:32,  1.03it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  61%|██████    | 48/79 [00:44<00:28,  1.07it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  63%|██████▎   | 50/79 [00:44<00:26,  1.11it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  66%|██████▌   | 52/79 [00:45<00:23,  1.15it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  68%|██████▊   | 54/79 [00:45<00:21,  1.19it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  71%|███████   | 56/79 [00:45<00:18,  1.23it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  73%|███████▎  | 58/79 [00:45<00:16,  1.27it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  76%|███████▌  | 60/79 [00:45<00:14,  1.31it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  78%|███████▊  | 62/79 [00:46<00:12,  1.34it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  81%|████████  | 64/79 [00:46<00:10,  1.38it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  84%|████████▎ | 66/79 [00:46<00:09,  1.42it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  86%|████████▌ | 68/79 [00:46<00:07,  1.46it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  89%|████████▊ | 70/79 [00:46<00:06,  1.50it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  91%|█████████ | 72/79 [00:47<00:04,  1.53it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  94%|█████████▎| 74/79 [00:47<00:03,  1.57it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  96%|█████████▌| 76/79 [00:47<00:01,  1.61it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30:  99%|█████████▊| 78/79 [00:47<00:00,  1.64it/s, loss=18.4, v_num=7, val_loss=26.80, train_loss_step=20.80, train_loss_epoch=18.10]\n",
      "Epoch 30: 100%|██████████| 79/79 [00:49<00:00,  1.60it/s, loss=18.4, v_num=7, val_loss=26.90, train_loss_step=17.50, train_loss_epoch=18.40]\n",
      "Epoch 31:  39%|███▉      | 31/79 [00:26<00:41,  1.16it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  41%|████      | 32/79 [00:45<01:07,  1.43s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  42%|████▏     | 33/79 [00:45<01:03,  1.39s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  43%|████▎     | 34/79 [00:45<01:00,  1.35s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  44%|████▍     | 35/79 [00:46<00:57,  1.32s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  46%|████▌     | 36/79 [00:46<00:55,  1.28s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  48%|████▊     | 38/79 [00:46<00:49,  1.22s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  51%|█████     | 40/79 [00:46<00:45,  1.16s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  53%|█████▎    | 42/79 [00:46<00:41,  1.11s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  56%|█████▌    | 44/79 [00:46<00:37,  1.07s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  58%|█████▊    | 46/79 [00:47<00:33,  1.02s/it, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  61%|██████    | 48/79 [00:47<00:30,  1.02it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  63%|██████▎   | 50/79 [00:47<00:27,  1.05it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  66%|██████▌   | 52/79 [00:47<00:24,  1.09it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  68%|██████▊   | 54/79 [00:47<00:22,  1.13it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  71%|███████   | 56/79 [00:48<00:19,  1.17it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  73%|███████▎  | 58/79 [00:48<00:17,  1.20it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  76%|███████▌  | 60/79 [00:48<00:15,  1.24it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  78%|███████▊  | 62/79 [00:48<00:13,  1.28it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  81%|████████  | 64/79 [00:48<00:11,  1.31it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  84%|████████▎ | 66/79 [00:48<00:09,  1.35it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  86%|████████▌ | 68/79 [00:48<00:07,  1.39it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  89%|████████▊ | 70/79 [00:49<00:06,  1.43it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  91%|█████████ | 72/79 [00:49<00:04,  1.46it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  94%|█████████▎| 74/79 [00:49<00:03,  1.50it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  96%|█████████▌| 76/79 [00:49<00:01,  1.53it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31:  99%|█████████▊| 78/79 [00:49<00:00,  1.57it/s, loss=18.9, v_num=7, val_loss=26.90, train_loss_step=23.00, train_loss_epoch=18.40]\n",
      "Epoch 31: 100%|██████████| 79/79 [00:51<00:00,  1.54it/s, loss=18.9, v_num=7, val_loss=27.10, train_loss_step=20.50, train_loss_epoch=19.00]\n",
      "Epoch 32:  39%|███▉      | 31/79 [00:25<00:40,  1.19it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  41%|████      | 32/79 [00:44<01:05,  1.38s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  42%|████▏     | 33/79 [00:44<01:01,  1.35s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  43%|████▎     | 34/79 [00:44<00:58,  1.31s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  44%|████▍     | 35/79 [00:44<00:56,  1.28s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  47%|████▋     | 37/79 [00:44<00:50,  1.21s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  49%|████▉     | 39/79 [00:45<00:46,  1.15s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  52%|█████▏    | 41/79 [00:45<00:41,  1.10s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  54%|█████▍    | 43/79 [00:45<00:38,  1.06s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  57%|█████▋    | 45/79 [00:45<00:34,  1.01s/it, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  59%|█████▉    | 47/79 [00:45<00:31,  1.03it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  62%|██████▏   | 49/79 [00:45<00:28,  1.07it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  65%|██████▍   | 51/79 [00:46<00:25,  1.11it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  67%|██████▋   | 53/79 [00:46<00:22,  1.14it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  70%|██████▉   | 55/79 [00:46<00:20,  1.18it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  72%|███████▏  | 57/79 [00:46<00:17,  1.22it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  75%|███████▍  | 59/79 [00:46<00:15,  1.26it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  77%|███████▋  | 61/79 [00:46<00:13,  1.30it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  80%|███████▉  | 63/79 [00:47<00:11,  1.34it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  82%|████████▏ | 65/79 [00:47<00:10,  1.37it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  85%|████████▍ | 67/79 [00:47<00:08,  1.41it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  87%|████████▋ | 69/79 [00:47<00:06,  1.45it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  90%|████████▉ | 71/79 [00:47<00:05,  1.49it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  92%|█████████▏| 73/79 [00:47<00:03,  1.52it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  95%|█████████▍| 75/79 [00:48<00:02,  1.56it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32:  97%|█████████▋| 77/79 [00:48<00:01,  1.60it/s, loss=19.5, v_num=7, val_loss=27.10, train_loss_step=18.60, train_loss_epoch=19.00]\n",
      "Epoch 32: 100%|██████████| 79/79 [00:49<00:00,  1.58it/s, loss=19.5, v_num=7, val_loss=28.00, train_loss_step=18.80, train_loss_epoch=19.60]\n",
      "Epoch 33:  39%|███▉      | 31/79 [00:25<00:40,  1.20it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  41%|████      | 32/79 [00:44<01:04,  1.38s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  42%|████▏     | 33/79 [00:44<01:01,  1.34s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  44%|████▍     | 35/79 [00:44<00:55,  1.27s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  47%|████▋     | 37/79 [00:44<00:50,  1.21s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  49%|████▉     | 39/79 [00:44<00:45,  1.15s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  52%|█████▏    | 41/79 [00:44<00:41,  1.10s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  54%|█████▍    | 43/79 [00:45<00:37,  1.05s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  57%|█████▋    | 45/79 [00:45<00:34,  1.01s/it, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  59%|█████▉    | 47/79 [00:45<00:30,  1.03it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  62%|██████▏   | 49/79 [00:45<00:27,  1.07it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  65%|██████▍   | 51/79 [00:45<00:25,  1.11it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  67%|██████▋   | 53/79 [00:46<00:22,  1.15it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  70%|██████▉   | 55/79 [00:46<00:20,  1.19it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  72%|███████▏  | 57/79 [00:46<00:17,  1.23it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  75%|███████▍  | 59/79 [00:46<00:15,  1.27it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  77%|███████▋  | 61/79 [00:46<00:13,  1.31it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  80%|███████▉  | 63/79 [00:46<00:11,  1.34it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  82%|████████▏ | 65/79 [00:47<00:10,  1.38it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  85%|████████▍ | 67/79 [00:47<00:08,  1.42it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  87%|████████▋ | 69/79 [00:47<00:06,  1.46it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  90%|████████▉ | 71/79 [00:47<00:05,  1.50it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  92%|█████████▏| 73/79 [00:47<00:03,  1.53it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:  95%|█████████▍| 75/79 [00:47<00:02,  1.57it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33:  97%|█████████▋| 77/79 [00:47<00:01,  1.61it/s, loss=20.1, v_num=7, val_loss=28.00, train_loss_step=19.40, train_loss_epoch=19.60]\n",
      "Epoch 33: 100%|██████████| 79/79 [00:49<00:00,  1.58it/s, loss=20.1, v_num=7, val_loss=27.70, train_loss_step=17.30, train_loss_epoch=20.10]\n",
      "Epoch 34:  39%|███▉      | 31/79 [00:25<00:38,  1.23it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  41%|████      | 32/79 [00:43<01:03,  1.36s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  42%|████▏     | 33/79 [00:43<01:00,  1.32s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  43%|████▎     | 34/79 [00:43<00:57,  1.29s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  46%|████▌     | 36/79 [00:43<00:52,  1.22s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  48%|████▊     | 38/79 [00:44<00:47,  1.16s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  51%|█████     | 40/79 [00:44<00:43,  1.11s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  53%|█████▎    | 42/79 [00:44<00:39,  1.06s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  56%|█████▌    | 44/79 [00:44<00:35,  1.02s/it, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  58%|█████▊    | 46/79 [00:44<00:32,  1.03it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  61%|██████    | 48/79 [00:44<00:29,  1.07it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  63%|██████▎   | 50/79 [00:45<00:26,  1.11it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  66%|██████▌   | 52/79 [00:45<00:23,  1.15it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  68%|██████▊   | 54/79 [00:45<00:21,  1.19it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  71%|███████   | 56/79 [00:45<00:18,  1.23it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  73%|███████▎  | 58/79 [00:45<00:16,  1.27it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  76%|███████▌  | 60/79 [00:45<00:14,  1.30it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  78%|███████▊  | 62/79 [00:46<00:12,  1.34it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  81%|████████  | 64/79 [00:46<00:10,  1.38it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  84%|████████▎ | 66/79 [00:46<00:09,  1.42it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  86%|████████▌ | 68/79 [00:46<00:07,  1.46it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  89%|████████▊ | 70/79 [00:46<00:06,  1.50it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  91%|█████████ | 72/79 [00:46<00:04,  1.53it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  94%|█████████▎| 74/79 [00:47<00:03,  1.57it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  96%|█████████▌| 76/79 [00:47<00:01,  1.61it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34:  99%|█████████▊| 78/79 [00:47<00:00,  1.65it/s, loss=18.9, v_num=7, val_loss=27.70, train_loss_step=17.80, train_loss_epoch=20.10]\n",
      "Epoch 34: 100%|██████████| 79/79 [00:48<00:00,  1.61it/s, loss=18.9, v_num=7, val_loss=27.60, train_loss_step=16.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  39%|███▉      | 31/79 [00:24<00:38,  1.25it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  41%|████      | 32/79 [00:43<01:03,  1.35s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  42%|████▏     | 33/79 [00:43<01:00,  1.32s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  43%|████▎     | 34/79 [00:43<00:57,  1.28s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  46%|████▌     | 36/79 [00:43<00:52,  1.22s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  48%|████▊     | 38/79 [00:43<00:47,  1.16s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  51%|█████     | 40/79 [00:44<00:42,  1.10s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  53%|█████▎    | 42/79 [00:44<00:39,  1.06s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  56%|█████▌    | 44/79 [00:44<00:35,  1.01s/it, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  58%|█████▊    | 46/79 [00:44<00:32,  1.03it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  61%|██████    | 48/79 [00:44<00:28,  1.07it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  63%|██████▎   | 50/79 [00:44<00:26,  1.11it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  66%|██████▌   | 52/79 [00:45<00:23,  1.15it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  68%|██████▊   | 54/79 [00:45<00:21,  1.19it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  71%|███████   | 56/79 [00:45<00:18,  1.23it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  73%|███████▎  | 58/79 [00:45<00:16,  1.27it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  76%|███████▌  | 60/79 [00:45<00:14,  1.31it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  78%|███████▊  | 62/79 [00:46<00:12,  1.35it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  81%|████████  | 64/79 [00:46<00:10,  1.38it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  84%|████████▎ | 66/79 [00:46<00:09,  1.42it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  86%|████████▌ | 68/79 [00:46<00:07,  1.46it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  89%|████████▊ | 70/79 [00:46<00:05,  1.50it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  91%|█████████ | 72/79 [00:46<00:04,  1.54it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  94%|█████████▎| 74/79 [00:46<00:03,  1.58it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  96%|█████████▌| 76/79 [00:47<00:01,  1.61it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35:  99%|█████████▊| 78/79 [00:47<00:00,  1.65it/s, loss=19.2, v_num=7, val_loss=27.60, train_loss_step=17.60, train_loss_epoch=18.80]\n",
      "Epoch 35: 100%|██████████| 79/79 [00:50<00:00,  1.55it/s, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=18.80, train_loss_epoch=19.20]\n",
      "Epoch 36:  39%|███▉      | 31/79 [00:26<00:40,  1.18it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  41%|████      | 32/79 [00:44<01:05,  1.40s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  42%|████▏     | 33/79 [00:44<01:02,  1.36s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  44%|████▍     | 35/79 [00:45<00:56,  1.29s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  47%|████▋     | 37/79 [00:45<00:51,  1.22s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  49%|████▉     | 39/79 [00:45<00:46,  1.16s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  52%|█████▏    | 41/79 [00:45<00:42,  1.11s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  54%|█████▍    | 43/79 [00:45<00:38,  1.06s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  57%|█████▋    | 45/79 [00:45<00:34,  1.02s/it, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  59%|█████▉    | 47/79 [00:46<00:31,  1.02it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  62%|██████▏   | 49/79 [00:46<00:28,  1.06it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  65%|██████▍   | 51/79 [00:46<00:25,  1.10it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  67%|██████▋   | 53/79 [00:46<00:22,  1.14it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  70%|██████▉   | 55/79 [00:46<00:20,  1.18it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  72%|███████▏  | 57/79 [00:46<00:18,  1.21it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  75%|███████▍  | 59/79 [00:47<00:15,  1.25it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  77%|███████▋  | 61/79 [00:47<00:13,  1.29it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  80%|███████▉  | 63/79 [00:47<00:12,  1.33it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  82%|████████▏ | 65/79 [00:47<00:10,  1.36it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  85%|████████▍ | 67/79 [00:47<00:08,  1.40it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  87%|████████▋ | 69/79 [00:47<00:06,  1.44it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  90%|████████▉ | 71/79 [00:47<00:05,  1.48it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  92%|█████████▏| 73/79 [00:48<00:03,  1.51it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  95%|█████████▍| 75/79 [00:48<00:02,  1.55it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36:  97%|█████████▋| 77/79 [00:48<00:01,  1.59it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=19.70, train_loss_epoch=19.20]\n",
      "Epoch 36: 100%|██████████| 79/79 [00:50<00:00,  1.57it/s, loss=19, v_num=7, val_loss=27.50, train_loss_step=16.10, train_loss_epoch=19.30]\n",
      "Epoch 37:  39%|███▉      | 31/79 [17:18<26:48, 33.51s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  41%|████      | 32/79 [18:27<27:07, 34.62s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  42%|████▏     | 33/79 [18:29<25:45, 33.61s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  43%|████▎     | 34/79 [18:29<24:27, 32.62s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  46%|████▌     | 36/79 [18:29<22:05, 30.81s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  48%|████▊     | 38/79 [18:29<19:57, 29.20s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  51%|█████     | 40/79 [18:29<18:01, 27.74s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  53%|█████▎    | 42/79 [18:29<16:17, 26.42s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  56%|█████▌    | 44/79 [18:29<14:42, 25.23s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  58%|█████▊    | 46/79 [18:30<13:16, 24.13s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  61%|██████    | 48/79 [18:30<11:57, 23.13s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  63%|██████▎   | 50/79 [18:30<10:44, 22.21s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  66%|██████▌   | 52/79 [18:30<09:36, 21.36s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  68%|██████▊   | 54/79 [18:30<08:34, 20.57s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  71%|███████   | 56/79 [18:31<07:36, 19.84s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  73%|███████▎  | 58/79 [18:31<06:42, 19.16s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  76%|███████▌  | 60/79 [18:31<05:51, 18.53s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  78%|███████▊  | 62/79 [18:31<05:04, 17.93s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Validating:  65%|██████▌   | 32/49 [01:13<00:05,  3.38it/s]\u001b[A\n",
      "Epoch 37:  81%|████████  | 64/79 [18:32<04:20, 17.39s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  84%|████████▎ | 66/79 [18:33<03:39, 16.86s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  86%|████████▌ | 68/79 [18:33<03:00, 16.37s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  89%|████████▊ | 70/79 [18:33<02:23, 15.90s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  91%|█████████ | 72/79 [18:33<01:48, 15.46s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  94%|█████████▎| 74/79 [18:33<01:15, 15.05s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37:  97%|█████████▋| 77/79 [18:33<00:28, 14.46s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=19.90, train_loss_epoch=19.30]\n",
      "Epoch 37: 100%|██████████| 79/79 [18:38<00:00, 14.16s/it, loss=19.5, v_num=7, val_loss=27.50, train_loss_step=18.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  39%|███▉      | 31/79 [12:56<20:02, 25.04s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  41%|████      | 32/79 [13:25<19:43, 25.19s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  43%|████▎     | 34/79 [13:26<17:46, 23.71s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:  46%|████▌     | 36/79 [13:26<16:03, 22.40s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  48%|████▊     | 38/79 [13:26<14:30, 21.23s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  51%|█████     | 40/79 [13:26<13:06, 20.17s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  53%|█████▎    | 42/79 [13:26<11:50, 19.21s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  56%|█████▌    | 44/79 [13:27<10:42, 18.35s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  58%|█████▊    | 46/79 [13:27<09:39, 17.55s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  61%|██████    | 48/79 [13:27<08:41, 16.82s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  63%|██████▎   | 50/79 [13:27<07:48, 16.15s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  66%|██████▌   | 52/79 [13:28<06:59, 15.54s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  68%|██████▊   | 54/79 [13:28<06:14, 14.97s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Validating:  49%|████▉     | 24/49 [00:32<00:04,  5.66it/s]\u001b[A\n",
      "Epoch 38:  71%|███████   | 56/79 [13:28<05:32, 14.44s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Validating:  53%|█████▎    | 26/49 [00:32<00:03,  5.97it/s]\u001b[A\n",
      "Epoch 38:  73%|███████▎  | 58/79 [13:28<04:52, 13.94s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Validating:  57%|█████▋    | 28/49 [00:32<00:03,  6.78it/s]\u001b[A\n",
      "Epoch 38:  76%|███████▌  | 60/79 [13:29<04:16, 13.48s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Validating:  61%|██████    | 30/49 [00:32<00:02,  6.79it/s]\u001b[A\n",
      "Epoch 38:  78%|███████▊  | 62/79 [13:29<03:41, 13.06s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Validating:  65%|██████▌   | 32/49 [00:33<00:03,  4.97it/s]\u001b[A\n",
      "Epoch 38:  81%|████████  | 64/79 [13:29<03:09, 12.65s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  84%|████████▎ | 66/79 [13:29<02:39, 12.27s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  86%|████████▌ | 68/79 [13:30<02:11, 11.91s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  89%|████████▊ | 70/79 [13:30<01:44, 11.57s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  91%|█████████ | 72/79 [13:30<01:18, 11.26s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  94%|█████████▎| 74/79 [13:30<00:54, 10.95s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  96%|█████████▌| 76/79 [13:30<00:32, 10.67s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38:  99%|█████████▊| 78/79 [13:30<00:10, 10.40s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=19.80, train_loss_epoch=19.00]\n",
      "Epoch 38: 100%|██████████| 79/79 [13:32<00:00, 10.29s/it, loss=19.2, v_num=7, val_loss=27.50, train_loss_step=17.90, train_loss_epoch=19.20]\n",
      "Epoch 39:  39%|███▉      | 31/79 [00:31<00:49,  1.03s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  41%|████      | 32/79 [00:51<01:15,  1.61s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  43%|████▎     | 34/79 [00:51<01:08,  1.52s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  46%|████▌     | 36/79 [00:51<01:02,  1.44s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  48%|████▊     | 38/79 [00:52<00:56,  1.37s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  51%|█████     | 40/79 [00:52<00:50,  1.31s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  53%|█████▎    | 42/79 [00:52<00:46,  1.25s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  56%|█████▌    | 44/79 [00:52<00:41,  1.20s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  58%|█████▊    | 46/79 [00:52<00:37,  1.15s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  61%|██████    | 48/79 [00:52<00:34,  1.10s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  63%|██████▎   | 50/79 [00:53<00:30,  1.06s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  66%|██████▌   | 52/79 [00:53<00:27,  1.02s/it, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  68%|██████▊   | 54/79 [00:53<00:24,  1.01it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  71%|███████   | 56/79 [00:53<00:21,  1.05it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  73%|███████▎  | 58/79 [00:53<00:19,  1.08it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  76%|███████▌  | 60/79 [00:53<00:17,  1.12it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  78%|███████▊  | 62/79 [00:54<00:14,  1.15it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  81%|████████  | 64/79 [00:54<00:12,  1.18it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  84%|████████▎ | 66/79 [00:54<00:10,  1.22it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  86%|████████▌ | 68/79 [00:54<00:08,  1.25it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  89%|████████▊ | 70/79 [00:54<00:07,  1.28it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  91%|█████████ | 72/79 [00:54<00:05,  1.32it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  94%|█████████▎| 74/79 [00:54<00:03,  1.35it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  96%|█████████▌| 76/79 [00:54<00:02,  1.38it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39:  99%|█████████▊| 78/79 [00:55<00:00,  1.42it/s, loss=19.1, v_num=7, val_loss=27.50, train_loss_step=20.80, train_loss_epoch=19.20]\n",
      "Epoch 39: 100%|██████████| 79/79 [00:56<00:00,  1.39it/s, loss=19.1, v_num=7, val_loss=27.40, train_loss_step=18.00, train_loss_epoch=19.10]\n",
      "Epoch 39: 100%|██████████| 79/79 [00:57<00:00,  1.37it/s, loss=19.1, v_num=7, val_loss=27.40, train_loss_step=18.00, train_loss_epoch=19.10]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b71bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
