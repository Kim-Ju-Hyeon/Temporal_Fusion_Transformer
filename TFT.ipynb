{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b62984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8476c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../M5_Dataset/level_12.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68478d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 20 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   id            int16  \n",
      " 1   item_id       int16  \n",
      " 2   dept_id       int8   \n",
      " 3   cat_id        int8   \n",
      " 4   store_id      int8   \n",
      " 5   state_id      int8   \n",
      " 6   d             int16  \n",
      " 7   sold          int16  \n",
      " 8   weekday       int8   \n",
      " 9   wday          int8   \n",
      " 10  month         int8   \n",
      " 11  year          int16  \n",
      " 12  event_name_1  int8   \n",
      " 13  event_type_1  int8   \n",
      " 14  event_name_2  int8   \n",
      " 15  event_type_2  int8   \n",
      " 16  snap_CA       int8   \n",
      " 17  snap_TX       int8   \n",
      " 18  snap_WI       int8   \n",
      " 19  sell_price    float16\n",
      "dtypes: float16(1), int16(5), int8(14)\n",
      "memory usage: 1.9 GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89db85c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id  d  sold  weekday  \\\n",
       "0  14370     1437        3       1         0         0  1     0        2   \n",
       "1  14380     1438        3       1         0         0  1     0        2   \n",
       "2  14390     1439        3       1         0         0  1     0        2   \n",
       "3  14400     1440        3       1         0         0  1     0        2   \n",
       "4  14410     1441        3       1         0         0  1     0        2   \n",
       "\n",
       "   wday  month  year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n",
       "0     1      1  2011            -1            -1            -1            -1   \n",
       "1     1      1  2011            -1            -1            -1            -1   \n",
       "2     1      1  2011            -1            -1            -1            -1   \n",
       "3     1      1  2011            -1            -1            -1            -1   \n",
       "4     1      1  2011            -1            -1            -1            -1   \n",
       "\n",
       "   snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0        0        0        0         0.0  \n",
       "1        0        0        0         0.0  \n",
       "2        0        0        0         0.0  \n",
       "3        0        0        0         0.0  \n",
       "4        0        0        0         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc423db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"id\"] = data[\"id\"].astype(str).astype(\"category\")\n",
    "data[\"item_id\"] = data[\"item_id\"].astype(str).astype(\"category\")\n",
    "data[\"dept_id\"] = data[\"dept_id\"].astype(str).astype(\"category\")\n",
    "data[\"cat_id\"] = data[\"cat_id\"].astype(str).astype(\"category\")\n",
    "data[\"store_id\"] = data[\"store_id\"].astype(str).astype(\"category\")\n",
    "data[\"state_id\"] = data[\"state_id\"].astype(str).astype(\"category\")\n",
    "data[\"weekday\"] = data[\"weekday\"].astype(str).astype(\"category\")\n",
    "data[\"wday\"] = data[\"wday\"].astype(str).astype(\"category\")\n",
    "data[\"month\"] = data[\"month\"].astype(str).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5cf4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_days = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "snap_days = ['snap_CA', 'snap_TX', 'snap_WI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c54561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[snap_days] = data[snap_days].astype(str).astype(\"category\")\n",
    "data[special_days] = data[special_days].astype(str).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda03e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data[data.d < 1912]\n",
    "test_dataset = data[data.d >= 1912]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac627f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 30\n",
    "max_encoder_length = 90\n",
    "training_cutoff = train_dataset[\"d\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c6ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder = train_dataset[lambda x: x.d > x.d.max() - max_encoder_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d92af6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.concat([test_encoder, test_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad6ea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cutoff = test_dataset[\"d\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605f11bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6208d269f320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_dataset[lambda x: x.d <= training_cutoff],\n",
    "    time_idx=\"d\",\n",
    "    target=\"sold\",\n",
    "    group_ids=[\"id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=['item_id', \"store_id\", \"dept_id\", \"state_id\", 'cat_id'],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\", \"weekday\", \"wday\", \"month\", \"snap_days\"],\n",
    "    variable_groups={\"special_days\": special_days, \"snap_days\": snap_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"sell_price\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"sold\"],\n",
    "\n",
    "    add_relative_time_idx=False,\n",
    "    add_target_scales=False,\n",
    "    add_encoder_length=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6859a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders for model\n",
    "batch_size = 128\n",
    "\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "val_dataloader = test_dataset.to_dataloader(train=False, batch_size=batch_size , num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(22)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=4,\n",
    "    dropout=0.3,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a46bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=20, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    gpus=0,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=res.suggestion(),\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.3,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b71bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
